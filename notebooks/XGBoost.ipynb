{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing, load_digits, load_iris\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "import pandas as pd\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "df = pd.read_csv('entities-2023-09-02_17 33 41.csv', usecols=['start', 'mean'])\n",
    "# df = pd.read_csv('entities-2023-09-06_10 17 37.csv', usecols=['start', 'mean'])\n",
    "df['start'] = pd.to_datetime(df['start'], format='%Y-%m-%d %H:%M:%S')\n",
    "df = df.set_index('start')\n",
    "df = df.asfreq(freq='H')\n",
    "df = df.tail(9*7*24)\n",
    "\n",
    "plot_pacf(df[\"mean\"], lags=24)\n",
    "\n",
    "df['hour'] = df.index.hour\n",
    "df['dayofweek'] = df.index.dayofweek\n",
    "df['is_weekend'] = (df.index.dayofweek >= 5)\n",
    "df['is_weekend'] = df['is_weekend'].replace({True: 1, False: 0})\n",
    "# df['day_so_far'] = df.groupby(df.index.day)['mean'].cumsum()\n",
    "df['past_24h'] = df['mean'].rolling(24).sum().shift()\n",
    "df['yesterday'] = df.groupby(df.index.date)['mean'].sum().shift(-1)\n",
    "df['yesterday'] = df['yesterday'].fillna(method='ffill')\n",
    "df['week_of_year'] = df.index.isocalendar().week\n",
    "df['lag_1h'] = df['mean'].shift(1)\n",
    "exogs = ['hour', 'yesterday', 'dayofweek', 'week_of_year']\n",
    "\n",
    "# train_period = 24 * 7 * 9\n",
    "train_period = 24*7*6\n",
    "# # for x in range(7*3):\n",
    "for x in range(0, len(df) - train_period, 24):\n",
    "    train_start = x\n",
    "    train_end = x + train_period\n",
    "    predict_start = df.iloc[train_end].name\n",
    "\n",
    "    print(f\"Training from {train_start} - {train_end - 1}: {df.iloc[train_start].name} - {df.iloc[train_end - 1].name}\")\n",
    "\n",
    "    X_train = df[train_start:train_end][exogs]\n",
    "    y_train = df[train_start:train_end]['mean']\n",
    "\n",
    "    X_test = df[train_end:train_end+24][exogs]\n",
    "    y_test = df[train_end:train_end+24]['mean']\n",
    "\n",
    "    model = xgb.XGBRegressor(verbosity=0, objective=\"reg:absoluteerror\", reg_alpha=0.1)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=False)\n",
    "\n",
    "    # xgb.plot_importance(model, height=0.9)\n",
    "\n",
    "    prediction = model.predict(X_test)\n",
    "    forecasted_df = pd.DataFrame(prediction, columns=['predicted'], index=pd.date_range(predict_start, predict_start + pd.Timedelta(hours=23), freq='H'))\n",
    "    df = df.combine_first(forecasted_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from matplotlib import pyplot\n",
    "\n",
    "df = df[['mean', 'predicted']]\n",
    "\n",
    "pyplot.figure()\n",
    "fig, ax = pyplot.subplots(figsize=(15, 5))\n",
    "df[train_period-48:]['mean'].plot(ax=ax)\n",
    "df[train_period-48:]['predicted'].plot(ax=ax)\n",
    "# (df[train_period-48:]['mean'] - df[train_period-48:]['predicted']).plot(ax=ax)\n",
    "# ax.fill_between(df.index, df['predicted_lower'], df['predicted_upper'], color='k', alpha=0.1);  \n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "daily_sums = df[train_period:].resample('D').sum()\n",
    "print(mean_absolute_error(df[train_period:]['mean'], df[train_period:]['predicted']))\n",
    "print(daily_sums)\n",
    "print(mean_squared_error(daily_sums['mean'], daily_sums['predicted']))\n",
    "print(mean_absolute_error(daily_sums['mean'], daily_sums['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "from numpy import fmin\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "df = pd.read_csv('entities-2023-09-02_17 33 41.csv', usecols=['start', 'mean'])\n",
    "# df = pd.read_csv('entities-2023-09-06_10 17 37.csv', usecols=['start', 'mean'])\n",
    "df['start'] = pd.to_datetime(df['start'], format='%Y-%m-%d %H:%M:%S')\n",
    "df = df.set_index('start')\n",
    "df = df.asfreq(freq='H')\n",
    "df = df.tail(9*7*24)\n",
    "\n",
    "df['hour'] = df.index.hour\n",
    "df['dayofweek'] = df.index.dayofweek\n",
    "df['is_weekend'] = (df.index.dayofweek >= 5)\n",
    "df['is_weekend'] = df['is_weekend'].replace({True: 1, False: 0})\n",
    "df['yesterday'] = df.groupby(df.index.date)['mean'].sum().shift(-1)\n",
    "df['yesterday'] = df['yesterday'].fillna(method='ffill')\n",
    "df['week_of_year'] = df.index.isocalendar().week\n",
    "\n",
    "mlflow.xgboost.autolog(silent=True)\n",
    "\n",
    "train_period = 24*7*4\n",
    "test_period = 24*7*3\n",
    "\n",
    "train = df[:train_period]\n",
    "test = df[train_period:train_period]\n",
    "\n",
    "X_train = train.drop(columns=\"mean\")\n",
    "X_test = test.drop(columns=\"mean\")\n",
    "y_train = train[\"mean\"]\n",
    "y_test = test[\"mean\"]\n",
    "\n",
    "train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "test = xgb.DMatrix(data=X_test, label=y_test)\n",
    "\n",
    "search_space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -7, 0),\n",
    "    'max_depth': scope.int(hp.uniform('max_depth', 1, 100)),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -2, 3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'gamma': hp.loguniform('gamma', -10, 10),\n",
    "    'alpha': hp.loguniform('alpha', -10, 10),\n",
    "    'lambda': hp.loguniform('lambda', -10, 10),\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'seed': 123,\n",
    "}\n",
    "\n",
    "def train_model(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        booster = xgb.train(params=params, dtrain=train, num_boost_round=5000, evals=[(test, \"test\")], early_stopping_rounds=50, verbose_eval=False)\n",
    "\n",
    "        # Record AUC as primary loss for Hyperopt to minimize\n",
    "        predictions_test = booster.predict(test)\n",
    "        auc_score = roc_auc_score(y_test, predictions_test)\n",
    "\n",
    "        # Set the loss to -1*auc_score so fmin maximizes the auc_score\n",
    "        return {'status': STATUS_OK, 'loss': -auc_score, 'booster': booster.attributes()}\n",
    "    \n",
    "with mlflow.start_run(run_name='initial_search'):\n",
    "    best_params = fmin(\n",
    "      fn=train_model,\n",
    "      space=search_space,\n",
    "      algo=tpe.suggest,\n",
    "      max_evals=25,\n",
    "    #   rstate=np.random.RandomState(123),\n",
    "      #trials=spark_trials\n",
    "    )\n",
    "\n",
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
